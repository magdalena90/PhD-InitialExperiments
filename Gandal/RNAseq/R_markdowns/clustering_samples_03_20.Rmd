---
title: "Clustering Samples"
# author: "Magdalena Navarro"
date: "19 March 2019"
output:
  html_document:
    code_folding: "hide"
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

Filter criteria:

- Filter differentially expressed genes between autism and control (**adjusted** p-value < 0.05)

- No samples are removed based on network connectivity z-scores

```{r, echo=TRUE, include=FALSE}
# setwd('/home/magdalena/PhD/initialExperiments/Gandal/RNAseq/R_markdowns')
setwd('/afs/inf.ed.ac.uk/user/s17/s1725186/Documents/PhD-InitialExperiments/Gandal/RNAseq/R_markdowns')

library(limma);
library(tidyverse) ; library(reshape2) ; library(glue) ; library(plotly) ; library(dendextend)
library(viridis)
library(ConsensusClusterPlus)
library(JADE) ; library(MineICA) ; library(moments) ; library(fdrtool)
library(ClusterR)
library(WGCNA)
library(pdfCluster) ; library(gplots)

# # FILTER DE GENES
# load('./../working_data/RNAseq_ASD_4region_normalized.Rdata')
# 
# # Balance Groups by covariates, remove singular batches (none)
# to_keep = (datMeta$Subject_ID != 'AN03345') & !is.na(datMeta$Dx)
# table(to_keep)
# datMeta = datMeta[to_keep,]
# datExpr = datExpr[,to_keep]
# datSeq = datSeq[to_keep,]
# 
# # Select genes differentially expressed in ASD
# mod = model.matrix(~ Dx, data=datMeta)
# corfit = duplicateCorrelation(datExpr, mod, block=datMeta$Subject_ID)
# lmfit = lmFit(datExpr, design=mod, block=datMeta$Subject_ID, correlation=corfit$consensus)
# 
# fit = eBayes(lmfit, trend=T, robust=T)
# top_genes = topTable(fit, coef=2, number=nrow(datExpr))
# ordered_top_genes = top_genes[match(rownames(datExpr), rownames(top_genes)),]
# 
# ASD_pvals = rownames(ordered_top_genes)[ordered_top_genes$adj.P.Val<0.05]     # 17% of genes (3385)
# ASD_lfc = rownames(ordered_top_genes)[abs(ordered_top_genes$logFC)>log2(1.2)] # 33% of genes (7048)
# ASD_pvals_lfc = intersect(ASD_pvals, ASD_lfc)                                 # 14% of genes (2928)
# 
# datExpr = datExpr[match(ASD_pvals_lfc, rownames(datExpr)),]
#
# rm(corfit, fit, lmfit, mod, ASD_pvals, ASD_lfc, ASD_pvals_lfc, top_genes)

load('./../working_data/RNAseq_ASD_4region_DEgenes_adj_pval_lfc.Rdata')
```

```{r}
glue('Number of genes: ', nrow(datExpr), '\n',
     'Number of samples: ', ncol(datExpr), ' (', sum(datMeta$Diagnosis_=='ASD'), ' ASD, ',
     sum(datMeta$Diagnosis_!='ASD'), ' controls)')
```

### Dimensionality reduction using PCA

```{r, fig.width = 12}
reduce_dim_datExpr = function(datExpr, datMeta, var_explained=0.8, filter_controls=FALSE){

  datExpr = data.frame(datExpr)
  
  if(filter_controls){
    datMeta = datMeta %>% filter(Diagnosis_=='ASD')
    datExpr = datExpr %>% select(paste0('X', datMeta_ASD$Dissected_Sample_ID))
  }
  
  datExpr_pca = prcomp(t(datExpr), scale=TRUE)
  last_pc = data.frame(summary(datExpr_pca)$importance[3,]) %>% rownames_to_column(var='ID') %>% 
    filter(.[[2]] >= var_explained) %>% top_n(-1, ID)
  
  par(mfrow=c(1,2))
  plot(summary(datExpr_pca)$importance[2,], type='b')
  abline(v=substr(last_pc$ID, 3, nchar(last_pc$ID)), col='blue')
  plot(summary(datExpr_pca)$importance[3,], type='b')
  abline(h=var_explained, col='blue')
  
  print(glue('Keeping top ', substr(last_pc$ID, 3, nchar(last_pc$ID)), ' components that explain ',
             var_explained*100, '% of the variance'))
  
  datExpr_top_pc = datExpr_pca$x %>% data.frame %>% dplyr::select(PC1:last_pc$ID)
  
  return(list('datExpr'=datExpr_top_pc, 'datMeta'=datMeta, 'pca_output'=datExpr_pca))
}

reduce_dim_output = reduce_dim_datExpr(datExpr, datMeta)
datExpr_redDim = reduce_dim_output$datExpr
datMeta_redDim = reduce_dim_output$datMeta
pca_output = reduce_dim_output$pca_output

rm(datSeq, datProbes, reduce_dim_datExpr, reduce_dim_output, datExpr, datMeta)
```

### Clustering

```{r}
clusterings = list()
```
#### K-means Clustering
No recognisable best k, so chose k=5
```{r}
set.seed(123)
wss = sapply(1:15, function(k) kmeans(datExpr_redDim, k, nstart=25)$tot.withinss)
plot(wss, type='b', main='K-Means Clustering')
best_k = 4
abline(v = best_k, col='blue')

datExpr_k_means = kmeans(datExpr_redDim, best_k, nstart=25)
clusterings[['km']] = datExpr_k_means$cluster
```

#### Hierarchical Clustering

Chose k=7 as best number of clusters.

Clusters seem to be able to separate ASD and control samples pretty well and there are no noticeable patterns regarding sex, age or brain region in any cluster.

Younger ASD samples seem to be more similar to control samples than older ASD samples (pink cluster has most of the youngest samples), perhaps oder samples were only diagnosed in extreme cases and now milder ASD cases get diagnosed a well and milder cases have milder gene expression differences? The yellow cluster is made of young ASD samples. Most old ASD samples are also close together.

Colors:

- Diagnosis: Blue=control, Green=ASD

- Sex: Pink=Female, Blue=Male

- Brain region: Pink=Frontal, Green=Temporal, Blue=Parietal, Purple=Occipital

- Age: Purple=youngest, Yellow=oldest
```{r, fig.width = 12}
h_clusts = datExpr_redDim %>% dist %>% hclust %>% as.dendrogram
# h_clusts %>% plot
best_k = 6
clusterings[['hc']] = cutree(h_clusts, best_k)

create_viridis_dict = function(age){
  min_age = datMeta_redDim$Age %>% min
  max_age = datMeta_redDim$Age %>% max
  viridis_age_cols = viridis(max_age - min_age + 1)
  names(viridis_age_cols) = seq(min_age, max_age)
  
  return(viridis_age_cols)
}
viridis_age_cols = create_viridis_dict()

dend_meta = datMeta_redDim[match(gsub('X','',labels(h_clusts)), rownames(datMeta_redDim)),] %>% 
            mutate('Diagnosis' = ifelse(Diagnosis_=='CTL','#008080','#86b300'), # Blue control, Green ASD
                   'Sex' = ifelse(Sex=='F','#ff6666','#008ae6'),                # Pink Female, Blue Male
                   'Region' = case_when(Brain_lobe=='Frontal'~'#F8766D',        # ggplot defaults for 4 colours
                                        Brain_lobe=='Temporal'~'#7CAE00',
                                        Brain_lobe=='Parietal'~'#00BFC4',
                                        Brain_lobe=='Occipital'~'#C77CFF'),
                   'Age' = viridis_age_cols[as.character(Age)]) %>%            # Purple: young, Yellow: old
            dplyr::select(Age, Region, Sex, Diagnosis)
h_clusts %>% set('labels', rep('', nrow(datMeta_redDim))) %>% set('branches_k_color', k=best_k) %>% plot
colored_bars(colors=dend_meta)
```

#### Consensus Clustering

Samples are grouped into two big clusters. It wasn't clear which was the best number of subclusters for the first one, but the second one was clearer. Chose 6 and 8, respectively.

*Output plots in clustering_samples_03_20 folder
```{r echo=FALSE, message=FALSE}
cc_output = datExpr_redDim %>% as.matrix %>% t %>% 
  ConsensusClusterPlus(maxK=5, reps=50, seed=123, title='clustering_samples_03_20/cc_l1/', plot='png')
best_k = 2
clusterings[['cc_l1']] = cc_output[[best_k]]$consensusClass

clusterings[['cc_l2']] = clusterings[['cc_l1']]
cc_output_c1 = datExpr_redDim %>% filter(clusterings[['cc_l1']]==1) %>% as.matrix %>% t %>% 
  ConsensusClusterPlus(maxK=15, reps=50, seed=123, title='clustering_samples_03_20/cc_l2_1/', plot='png')
best_k = 6
clusterings[['cc_l2']][clusterings[['cc_l1']]==1] = cc_output_c1[[best_k]]$consensusClass %>% 
                                                    sapply(function(x) glue('1_', x))

cc_output_c2 = datExpr_redDim %>% filter(clusterings[['cc_l1']]==2) %>% as.matrix %>% t %>% 
  ConsensusClusterPlus(maxK=10, reps=50, seed=123, title='clustering_samples_03_20/cc_l2_2/', plot='png')
best_k = 8
clusterings[['cc_l2']][clusterings[['cc_l1']]==2] = cc_output_c2[[best_k]]$consensusClass %>% 
                                                    sapply(function(x) glue('2_', x))
```

#### Independent Component Analysis

Following [this paper's](www.journals.plos.org/plosgenetics/article?id=10.1371/journal.pgen.1002367) guidelines:

0. Run PCA and keep enough components to explain 60% of the variance

1. Run ICA with that same number of nbComp as principal components kept to then filter them

2. Select components with kurtosis > 3

3. Assign obs to genes with FDR<0.01 using the fdrtool package

```{r echo=FALSE, message=FALSE, warning=FALSE}
ICA_output = datExpr_redDim %>% runICA(nbComp=ncol(datExpr_redDim), method='JADE')
signals_w_kurtosis = ICA_output$S %>% data.frame %>% dplyr::select(names(apply(ICA_output$S, 2, kurtosis)>3))
ICA_clusters = apply(signals_w_kurtosis, 2, function(x) fdrtool(x, plot=F)$qval<0.01) %>% data.frame
ICA_clusters = ICA_clusters[colSums(ICA_clusters)>1]

clusterings[['ICA_min']] = rep(NA, nrow(ICA_clusters))
ICA_clusters_names = colnames(ICA_clusters)
for(c in ICA_clusters_names) clusterings[['ICA_min']][ICA_clusters[,c]] = c
```

Not a good method for clustering samples because:

1. ICA does not perform well with small samples (see [Figure 4](https://www.nature.com/articles/s41467-018-03424-4/figures/4) of [this paper](https://www.nature.com/articles/s41467-018-03424-4))

2. Warnings: (Warning in fdrtool(x, plot = F): There may be too few input test statistics for reliable FDR calculations!)

3. Leaves almost half of the observations (40) without a cluster, which is better than with the past datasets, but it's still a lot:
```{r}
ICA_clusters %>% rowSums %>% table

ICA_clusters %>% mutate(cl_sum=rowSums(.)) %>% as.matrix %>% melt %>% ggplot(aes(Var2,Var1)) + 
  geom_tile(aes(fill=value)) + xlab('Clusters') + ylab('Samples') + 
  theme_minimal() + theme(axis.text.x=element_blank(), axis.ticks.x=element_blank()) + coord_flip()
```

#### WGCNA

SFT.R.sq starts in 0.8 with power=1 but at 2 decreases to 0.28 and starts slowly growing. Best power=21.

```{r, warning=FALSE}
best_power = datExpr_redDim %>% t %>% pickSoftThreshold(powerVector = seq(2, 26, by=2))
network = datExpr_redDim %>% t %>% blockwiseModules(power=best_power$powerEstimate, numericLabels=TRUE)
clusterings[['WGCNA']] = network$colors
names(clusterings[['WGCNA']]) = rownames(datExpr_redDim)
```

It finds a single cluster grouping 66 observations and leaves the rest without cluster:
```{r}
table(clusterings[['WGCNA']])
```

#### Gaussian Mixture Models with hard thresholding

Points don't seem to follow a Gaussian distribution no matter the number of clusters, chose 4 points following the best k from K-means because the methods are similar

```{r}
n_clust = datExpr_redDim %>% Optimal_Clusters_GMM(max_clusters=80, criterion='BIC', plot_data=FALSE)
plot(n_clust, type='l', main='Bayesian Information Criterion to choose number of clusters')
best_k = 4 # copying k-means best_k
gmm = datExpr_redDim %>% GMM(best_k)
clusterings[['GMM']] = gmm$Log_likelihood %>% apply(1, which.max)
```

Plot of clusters with their centroids in gray
```{r}
gmm_points = rbind(datExpr_redDim, setNames(data.frame(gmm$centroids), names(datExpr_redDim)))
gmm_labels = c(clusterings[['GMM']], rep(NA, best_k)) %>% as.factor
ggplotly(gmm_points %>% ggplot(aes(x=PC1, y=PC2, color=gmm_labels)) + geom_point() + theme_minimal())
```

```{r}
rm(wss, datExpr_k_means, h_clusts, cc_output, cc_output_c1, cc_output_c2, best_k, ICA_output, 
   ICA_clusters_names, signals_w_kurtosis, n_clust, gmm, gmm_points, gmm_labels, network, dend_meta, 
   best_power, c, viridis_age_cols, create_viridis_dict)
```

### Compare clusterings

Using Adjusted Rand Index: 

* All clusterings are pretty similar except for WGCNA and ICA

* K-means and Hierarchical clustering are the most similar

* ICA no longer seems to be clustering individuals together, but it appears to be leaving without a cluster the control samples

* Boolean of NA in ICA is the one with the strongest relation to ASD, followed by cc_l1
```{r}
clusters_plus_phenotype = clusterings
clusters_plus_phenotype[['ICA_NA']] = is.na(clusters_plus_phenotype[['ICA_min']])
clusters_plus_phenotype[['Subject']] = datMeta_redDim$Subject_ID
clusters_plus_phenotype[['ASD']] = datMeta_redDim$Diagnosis_
clusters_plus_phenotype[['Region']] = datMeta_redDim$Brain_lobe
clusters_plus_phenotype[['Sex']] = datMeta_redDim$Sex
clusters_plus_phenotype[['Age']] = datMeta_redDim$Age

cluster_sim = data.frame(matrix(nrow = length(clusters_plus_phenotype), ncol = length(clusters_plus_phenotype)))
for(i in 1:(length(clusters_plus_phenotype))){
  cluster1 = as.factor(clusters_plus_phenotype[[i]])
  for(j in (i):length(clusters_plus_phenotype)){
    cluster2 = as.factor(clusters_plus_phenotype[[j]])
    cluster_sim[i,j] = adj.rand.index(cluster1, cluster2)
  }
}
colnames(cluster_sim) = names(clusters_plus_phenotype)
rownames(cluster_sim) = colnames(cluster_sim)

cluster_sim = cluster_sim %>% as.matrix %>% round(2)
heatmap.2(x = cluster_sim, Rowv = FALSE, Colv = FALSE, dendrogram = 'none', 
          cellnote = cluster_sim, notecol = 'black', trace = 'none', key = FALSE, 
          cexRow = 1, cexCol = 1, margins = c(7,7))
 

rm(i, j, cluster1, cluster2, clusters_plus_phenotype, cluster_sim)
```

### Scatter plots

```{r}
create_2D_plot = function(cat_var){
 ggplotly(plot_points %>% ggplot(aes_string(x='PC1', y='PC2', color=cat_var)) + 
          geom_point() + theme_minimal() + 
          xlab(paste0('PC1 (', round(summary(pca_output)$importance[2,1]*100,2),'%)')) +
          ylab(paste0('PC2 (', round(summary(pca_output)$importance[2,2]*100,2),'%)')))
}
create_3D_plot = function(cat_var){
  plot_points %>% plot_ly(x=~PC1, y=~PC2, z=~PC3) %>% add_markers(color=plot_points[,cat_var], size=1) %>% 
    layout(title = glue('Samples coloured by ', cat_var),
           scene = list(xaxis=list(title=glue('PC1 (',round(summary(pca_output)$importance[2,1]*100,2),'%)')),
                        yaxis=list(title=glue('PC2 (',round(summary(pca_output)$importance[2,2]*100,2),'%)')),
                        zaxis=list(title=glue('PC3 (',round(summary(pca_output)$importance[2,3]*100,2),'%)'))))  
}

plot_points = datExpr_redDim %>% data.frame() %>% dplyr::select(PC1:PC3) %>%
              mutate(ID = rownames(.), subject_ID = datMeta_redDim$Subject_ID,
                km_clust = as.factor(clusterings[['km']]),       hc_clust = as.factor(clusterings[['hc']]),
                cc_l1_clust = as.factor(clusterings[['cc_l1']]), cc_clust = as.factor(clusterings[['cc_l2']]),
                ica_clust = as.factor(clusterings[['ICA_min']]), n_ica_clust = as.factor(rowSums(ICA_clusters)),
                gmm_clust = as.factor(clusterings[['GMM']]),     wgcna_clust = as.factor(clusterings[['WGCNA']]),
                sex = as.factor(datMeta_redDim$Sex),             region = as.factor(datMeta_redDim$Brain_lobe), 
                diagnosis = as.factor(datMeta_redDim$Diagnosis_), age = datMeta_redDim$Age)
```

#### 2D plots of clusterings
```{r}
create_2D_plot('km_clust')
create_2D_plot('hc_clust')
create_2D_plot('cc_l1_clust')
create_2D_plot('cc_clust')
create_2D_plot('ica_clust')
create_2D_plot('gmm_clust')
create_2D_plot('wgcna_clust')
```

#### 2D plots of Phenotypes
```{r}
create_2D_plot('diagnosis')
create_2D_plot('region')
create_2D_plot('sex')
create_2D_plot('age')
```

#### 3D plots
```{r, warning=FALSE}
create_3D_plot('ica_clust')
create_3D_plot('wgcna_clust')
```